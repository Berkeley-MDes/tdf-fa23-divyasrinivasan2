# Week 10 - 10/30 - AI Thoughts #

After working with GPT4 through Zero Width I had some thoughts: 

- Is AI as scary as I initially thought it was? I think right now, its not. I'm still not sure how far it can be taken where it can eventually be misused. However, since it does rely heavily on human intelligence, there is still a lot of room for people to use it the wrong way, although I think most companies try to prevent this through regulations. I think the bigger issue is when it goes beyond the intelligence it is given.

- I remember a podcast episode I listened to "The Godfather of A.I. has regrets" from The Daily, and it talks about how Geoffrey Hinton, who first built a neural net, and quit Google since he felt AI could end up quite scary.

- He says:
    - "... could be exploited by “bad actors”. “It’s able to produce lots of text automatically so you can get lots of very effective spambots. It will allow authoritarian leaders to manipulate their electorates, things like that.”
    - "If you ask a system to make money for you — which people, by the way, are already starting to do — can you use ChatGPT to make money on the stock market? As people do that, think of all the ways that you can make money. And think of all the ways that could go wrong." "Remember, these are machines. Machines are psychopaths. They don’t have emotions. They don’t have a moral compass. They do what you ask them to do. Make us money? OK, we’ll make you money. Perhaps you break into a computer system in order to steal that money. If you own oil futures in Central Africa, perhaps you foment a revolution to increase the price of those futures to make money from it."

- I wonder if there's a way to stop intelligence from growing and working in that capacity?

