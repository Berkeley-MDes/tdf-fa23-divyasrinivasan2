# Week 9 - 10/23 - Artifical Intelligence Chatbot #

This week, we explored the use of Artifical Intelligence chatbots beyond Chat GPT. Using GPT 4 we developed our own prompts, instruction and knowledge database for the chatbot to use. 
The demo in class was very interesting! It was my first time learning about things like:
- How these chatbots actually work
- Tokens
- Neural Networks
- Prompt Generation

I know that we only covered the basics, and I'm very curious what all the capabilities of a software like Zero Width could be. 
During the in-class demo, I was focusing on getting the chatbot to talk like I do in texts! It got pretty close (maybe too many slang phrases compared to what I would use, and needs finetuning) but I was impressed with how quickly it used acronyms in the right context. Here is the example of the instructions I gave, and the Intelligence's chat:

Instructions:
![Instruction_1](Images/Instruction_1.png)
![Instruction_2](Images/Instruction_2.png)
![Instruction_3](Images/Instruction_3.png)

Chat Example:
![Intelligence_Chat_1](Images/Intelligence_Chat_1.png)

# Talk by Anthropic #

I also attended a talk this week by Anthropic (a company started by previous members of OpenAI), where they talked about large language models, which was very timely given this week's project. Some of my key takeaways were:
- The use of LLM and how it is mostly focused on writing and language used in prompting.
- At Anthropic, they aim to be more ethical/trustworthy than Open AI, so they use something called "Constitutional AI".
- Unfortunately they didn't cover this topic, but essentially they use AI to supervise other AI.
- I find this interesting, and wonder how effective it is compared to other methods. Self-regulation has never ended well for most companies.
- I was shocked by the amount of money these engineers get, just for creating a product (Claud) that is similar to GPT. Well into the high six figures for a starting position. I feel uncomfortable that companies like this have this much money, in technology that isn't currently helping any pressing issues in the world, it feels like an ethical violation. 
